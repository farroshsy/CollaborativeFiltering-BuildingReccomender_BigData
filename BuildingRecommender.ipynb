{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "TpZ9D9SVj1YD"
   },
   "source": [
    "# **Big Data Assignment Week 9**\n",
    "## Building Recommender\n",
    "---\n",
    "\n",
    "Name: Farros Hilmi Syafei \n",
    "<br>\n",
    "Student ID: 5025201012\n",
    "<br>\n",
    "Class: Big Data A\n",
    "<br>\n",
    "Lecturer: Abdul Munif, S.Kom., M.Sc.\n",
    "\n",
    "\n",
    "Using: JupyterLab </br>\n",
    "Reference: https://github.com/jadianes/spark-movie-lens/blob/master/notebooks/building-recommender.ipynb"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "j2tUEl2ckB28"
   },
   "source": [
    "# An on-line movie recommending service using Spark & Flask - Building the recommender"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "luTl1Id_keby"
   },
   "source": [
    "This notebook explains how to use the [MovieLens dataset](http://grouplens.org/datasets/movielens/) to build a movie recommender using [collaborative filtering](https://en.wikipedia.org/wiki/Recommender_system#Collaborative_filtering) with [Spark's Alternating Least Saqures](https://spark.apache.org/docs/latest/mllib-collaborative-filtering.html) implementation. It is organised in two parts. The first one is about getting and parsing movies and ratings data into Spark RDDs. The second is about building and using the recommender and persisting it for later use in our on-line recommender system."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "MTwJmm7UkhNS"
   },
   "source": [
    "This tutorial can be used independently to build a movie recommender model based on the MovieLens dataset. Most of the code in this first part, about how to use ALS with the public MovieLens dataset, comes from my solution to one of the exercises proposed in the [CS100.1x Introduction to Big Data with Apache Spark by Anthony D. Joseph on edX](https://www.edx.org/course/introduction-big-data-apache-spark-uc-berkeleyx-cs100-1x), that is also [**publicly available since 2014 at Spark Summit**](https://databricks-training.s3.amazonaws.com/movie-recommendation-with-mllib.html) . There I've added with minor modifications to use a larger dataset and also code about how to store and reload the model for later use."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "XeFGH3tokG_w"
   },
   "source": [
    "## Getting and processing the data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "LxqON9sqkbR0"
   },
   "source": [
    "In order to build an on-line movie recommender using Spark, we need to have our model data as preprocessed as possible. Parsing the dataset and building the model everytime a new recommendation needs to be done is not the best of the strategies."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "FavSkGgEknlY"
   },
   "source": [
    "The list of task we can pre-compute includes:\n",
    "- Loading and parsing the dataset. Persisting the resulting RDD for later use.\n",
    "- Building the recommender model using the complete dataset. Persist the dataset for later use.\n",
    "\n",
    "</br>\n",
    "This notebook explains the first of these tasks."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "lqukIDBpmnhN"
   },
   "source": [
    "### File download"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "0k0tfkY2mr6J"
   },
   "source": [
    "GroupLens Research has collected and made available rating data sets from the [MovieLens web site](http://movielens.org). The data sets were collected over various periods of time, depending on the size of the set. They can be found [here](http://grouplens.org/datasets/movielens/)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ahIK3GVGmwAc"
   },
   "source": [
    "In our case, we will use the latest datasets:\n",
    "\n",
    "- Small: 100,000 ratings and 2,488 tag applications applied to 8,570 movies by 706 users. Last updated 4/2015.\n",
    "- Full: 21,000,000 ratings and 470,000 tag applications applied to 27,000 movies by 230,000 users. Last updated 4/2015."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "bhTU-uMejhFB"
   },
   "outputs": [],
   "source": [
    "complete_dataset_url = 'http://files.grouplens.org/datasets/movielens/ml-latest.zip'\n",
    "small_dataset_url = 'http://files.grouplens.org/datasets/movielens/ml-latest-small.zip'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "9qoyn6iRm7Fj"
   },
   "source": [
    "We also need to define download locations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "n5LbLD_fm7rR"
   },
   "outputs": [],
   "source": [
    "small_dataset_path = 'datasets/ml-latest-small.zip'\n",
    "complete_dataset_path = 'datasets/ml-latest.zip'\n",
    "\n",
    "import os\n",
    "if not os.path.exists('datasets'):\n",
    "    os.makedirs('datasets')\n",
    "\n",
    "datasets_path = os.path.join('..', 'datasets')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "j4GcCKeFnBTH"
   },
   "source": [
    "Now we can proceed with both downloads."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "nim___EUnBsc"
   },
   "outputs": [],
   "source": [
    "import urllib.request\n",
    "\n",
    "small_f = urllib.request.urlretrieve(small_dataset_url, small_dataset_path)\n",
    "complete_f = urllib.request.urlretrieve(complete_dataset_url, complete_dataset_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "p2xHJWlDqiFy"
   },
   "source": [
    "Both of them are zip files containing a folder with ratings, movies, etc. We need to extract them into its individual folders so we can use each file later on."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "-kzE1KlUqjEk"
   },
   "outputs": [],
   "source": [
    "import zipfile\n",
    "\n",
    "with zipfile.ZipFile(small_dataset_path, \"r\") as z:\n",
    "    z.extractall(datasets_path)\n",
    "\n",
    "with zipfile.ZipFile(complete_dataset_path, \"r\") as z:\n",
    "    z.extractall(datasets_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "K7oKG2lvq6Er",
    "tags": []
   },
   "source": [
    "### Loading and parsing datasets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "4wnc1ORKq7Rk"
   },
   "source": [
    "Each line in the ratings dataset (`ratings.csv`) is formatted as: </br> `userId,movieId,rating,timestamp` </br>\n",
    "</br>\n",
    "Each line in the movies (`movies.csv`) dataset is formatted as:  </br>\n",
    "</br>\n",
    "`movieId,title,genres`  </br>\n",
    "</br>\n",
    "Were *genres* has the format:  </br>\n",
    "</br>\n",
    "`Genre1|Genre2|Genre3...`</br>\n",
    "</br>\n",
    "The tags file (`tags.csv`) has the format:  </br>\n",
    "</br>\n",
    "`userId,movieId,tag,timestamp`  </br>\n",
    "</br>\n",
    "And finally, the `links.csv` file has the format:  </br>\n",
    "</br>\n",
    "`movieId,imdbId,tmdbId`  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "rceFGsoFr2Ls"
   },
   "source": [
    "The format of these files is uniform and simple, so we can use Python [`split()`](https://docs.python.org/2/library/stdtypes.html#str.split) to parse their lines once they are loaded into RDDs. Parsing the movies and ratings files yields two RDDs:  </br>\n",
    "* For each line in the ratings dataset, we create a tuple of `(UserID, MovieID, Rating)`. We drop the *timestamp* because we do not need it for this recommender.  </br>\n",
    "* For each line in the movies dataset, we create a tuple of `(MovieID, Title)`. We drop the *genres* because we do not use them for this recommender.  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "fv6O1bBIsDi3"
   },
   "source": [
    "So let's load the raw ratings data. We need to filter out the header, included in each file."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "R_r_ivCrs5bt"
   },
   "source": [
    "### Initialization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "23/04/14 01:52:27 WARN Utils: Your hostname, Farross-MacBook-Pro.local resolves to a loopback address: 127.0.0.1; using 192.168.0.9 instead (on interface en0)\n",
      "23/04/14 01:52:27 WARN Utils: Set SPARK_LOCAL_IP if you need to bind to another address\n",
      "WARNING: An illegal reflective access operation has occurred\n",
      "WARNING: Illegal reflective access by org.apache.spark.unsafe.Platform (file:/Applications/anaconda3/lib/python3.10/site-packages/pyspark/jars/spark-unsafe_2.12-3.2.1.jar) to constructor java.nio.DirectByteBuffer(long,int)\n",
      "WARNING: Please consider reporting this to the maintainers of org.apache.spark.unsafe.Platform\n",
      "WARNING: Use --illegal-access=warn to enable warnings of further illegal reflective access operations\n",
      "WARNING: All illegal access operations will be denied in a future release\n",
      "Using Spark's default log4j profile: org/apache/spark/log4j-defaults.properties\n",
      "Setting default log level to \"WARN\".\n",
      "To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).\n",
      "23/04/14 01:52:28 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "\n",
    "spark = SparkSession.builder \\\n",
    "        .appName(\"MyApp\") \\\n",
    "        .master(\"local[*]\") \\\n",
    "        .getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "id": "3-drzxnUsC2U"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "sc = spark.sparkContext\n",
    "\n",
    "small_ratings_file = os.path.join(datasets_path, 'ml-latest-small', 'ratings.csv')\n",
    "\n",
    "small_ratings_raw_data = sc.textFile(small_ratings_file)\n",
    "small_ratings_raw_data_header = small_ratings_raw_data.take(1)[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "raQLjjW7s9RT"
   },
   "source": [
    "Now we can parse the raw data into a new RDD."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "id": "75rlbkBks98I"
   },
   "outputs": [],
   "source": [
    "small_ratings_data = small_ratings_raw_data.filter(lambda line: line!=small_ratings_raw_data_header)\\\n",
    "    .map(lambda line: line.split(\",\")).map(lambda tokens: (tokens[0],tokens[1],tokens[2])).cache()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "XcDPPrT1tEr0"
   },
   "source": [
    "For illustrative purposes, we can take the first few lines of our RDD to see the result. In the final script we don't call any Spark action (e.g. `take`) until needed, since they trigger actual computations in the cluster."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "5iKS8AgVtFEq",
    "outputId": "fe1e094e-113b-4d7e-8e13-38d3c4fb36d3"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('1', '1', '4.0'), ('1', '3', '4.0'), ('1', '6', '4.0')]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "small_ratings_data.take(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "V9QXe6BHtODO"
   },
   "source": [
    "We proceed in a similar way with the `movies.csv` file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "c5PvWVlmtObL",
    "outputId": "9ef5d200-98d4-44c6-fc3f-2a49a1893a21"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('1', 'Toy Story (1995)'),\n",
       " ('2', 'Jumanji (1995)'),\n",
       " ('3', 'Grumpier Old Men (1995)')]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "small_movies_file = os.path.join(datasets_path, 'ml-latest-small', 'movies.csv')\n",
    "\n",
    "small_movies_raw_data = sc.textFile(small_movies_file)\n",
    "small_movies_raw_data_header = small_movies_raw_data.take(1)[0]\n",
    "\n",
    "small_movies_data = small_movies_raw_data.filter(lambda line: line!=small_movies_raw_data_header)\\\n",
    "    .map(lambda line: line.split(\",\")).map(lambda tokens: (tokens[0],tokens[1])).cache()\n",
    "    \n",
    "small_movies_data.take(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "aoGZGtuMtTQs"
   },
   "source": [
    "The following sections introduce Collaborative Filtering and explain how to use Spark MLlib to build a recommender model. We will close the tutorial by explaining how a model such this is used to make recommendations, and how to persist it for later use (e.g. in our Python/flask web-service)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ABAvQTp4tT5e"
   },
   "source": [
    "## Collaborative Filtering"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "xgSgHcKdttLz"
   },
   "source": [
    "In Collaborative filtering we make predictions (filtering) about the interests of a user by collecting preferences or taste information from many users (collaborating). The underlying assumption is that if a user A has the same opinion as a user B on an issue, A is more likely to have B's opinion on a different issue x than to have the opinion on x of a user chosen randomly."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "QXHeym9etttU"
   },
   "source": [
    "The image below (from [Wikipedia](https://en.wikipedia.org/?title=Collaborative_filtering)) shows an example of collaborative filtering. At first, people rate different items (like videos, images, games). Then, the system makes predictions about a user's rating for an item not rated yet. The new predictions are built upon the existing ratings of other users with similar ratings with the active user. In the image, the system predicts that the user will not like the video."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "BUIEgUket04I"
   },
   "source": [
    "![collaborative filtering](https://upload.wikimedia.org/wikipedia/commons/5/52/Collaborative_filtering.gif)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "gVMaxzMht4hS"
   },
   "source": [
    "Spark MLlib library for Machine Learning provides a [Collaborative Filtering](https://spark.apache.org/docs/latest/mllib-collaborative-filtering.html) implementation by using [Alternating Least Squares](http://dl.acm.org/citation.cfm?id=1608614). The implementation in MLlib has the following parameters:  </br>\n",
    "- numBlocks is the number of blocks used to parallelize computation (set to -1 to auto-configure).  \n",
    "- rank is the number of latent factors in the model.  \n",
    "- iterations is the number of iterations to run.  \n",
    "- lambda specifies the regularization parameter in ALS.  \n",
    "- implicitPrefs specifies whether to use the explicit feedback ALS variant or one adapted for implicit feedback data.  \n",
    "- alpha is a parameter applicable to the implicit feedback variant of ALS that governs the baseline confidence in preference observations."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "voxXEN81uH8l"
   },
   "source": [
    "## Selecting ALS parameters using the small dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "q_g8o4JsuK_q"
   },
   "source": [
    "In order to determine the best ALS parameters, we will use the small dataset. We need first to split it into train, validation, and test datasets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "id": "zF7VOytquNbB"
   },
   "outputs": [],
   "source": [
    "training_RDD, validation_RDD, test_RDD = small_ratings_data.randomSplit([6, 2, 2], seed=0)\n",
    "validation_for_predict_RDD = validation_RDD.map(lambda x: (x[0], x[1]))\n",
    "test_for_predict_RDD = test_RDD.map(lambda x: (x[0], x[1]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "EWtpBVOnue3W"
   },
   "source": [
    "Now we can proceed with the training phase."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "JMikDVbvufVe",
    "outputId": "df57496c-89f0-4c09-e5a1-a5f079a66631"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "23/04/14 01:52:36 WARN BlockManager: Task 4 already completed, not releasing lock for rdd_3_0\n",
      "23/04/14 01:52:37 WARN BlockManager: Task 5 already completed, not releasing lock for rdd_3_0\n",
      "23/04/14 01:52:38 WARN BlockManager: Task 6 already completed, not releasing lock for rdd_3_0\n",
      "23/04/14 01:52:42 WARN InstanceBuilder$NativeBLAS: Failed to load implementation from:dev.ludovic.netlib.blas.JNIBLAS\n",
      "23/04/14 01:52:42 WARN InstanceBuilder$NativeBLAS: Failed to load implementation from:dev.ludovic.netlib.blas.ForeignLinkerBLAS\n",
      "23/04/14 01:52:43 WARN InstanceBuilder$NativeLAPACK: Failed to load implementation from:dev.ludovic.netlib.lapack.JNILAPACK\n",
      "23/04/14 01:52:48 WARN BlockManager: Task 401 already completed, not releasing lock for rdd_3_0\n",
      "23/04/14 01:52:53 WARN BlockManager: Task 458 already completed, not releasing lock for rdd_3_0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For rank 4 the RMSE is 0.9136647249990393\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "23/04/14 01:52:54 WARN BlockManager: Task 459 already completed, not releasing lock for rdd_3_0\n",
      "23/04/14 01:52:55 WARN BlockManager: Task 460 already completed, not releasing lock for rdd_3_0\n",
      "23/04/14 01:53:00 WARN BlockManager: Task 855 already completed, not releasing lock for rdd_3_0\n",
      "23/04/14 01:53:03 WARN BlockManager: Task 912 already completed, not releasing lock for rdd_3_0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For rank 8 the RMSE is 0.9226236024336004\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "23/04/14 01:53:04 WARN BlockManager: Task 913 already completed, not releasing lock for rdd_3_0\n",
      "23/04/14 01:53:05 WARN BlockManager: Task 914 already completed, not releasing lock for rdd_3_0\n",
      "23/04/14 01:53:10 WARN BlockManager: Task 1309 already completed, not releasing lock for rdd_3_0\n",
      "[Stage 539:=============================================>         (15 + 3) / 18]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For rank 12 the RMSE is 0.9188432739535751\n",
      "The best model was trained with rank 4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "from pyspark.mllib.recommendation import ALS\n",
    "import math\n",
    "\n",
    "seed = 5\n",
    "iterations = 10\n",
    "regularization_parameter = 0.1\n",
    "ranks = [4, 8, 12]\n",
    "errors = [0, 0, 0]\n",
    "err = 0\n",
    "tolerance = 0.02\n",
    "\n",
    "min_error = float('inf')\n",
    "best_rank = -1\n",
    "best_iteration = -1\n",
    "for rank in ranks:\n",
    "    model = ALS.train(training_RDD, rank, seed=seed, iterations=iterations,\n",
    "                      lambda_=regularization_parameter)\n",
    "    predictions = model.predictAll(validation_for_predict_RDD).map(lambda r: ((r[0], r[1]), r[2]))\n",
    "    rates_and_preds = validation_RDD.map(lambda r: ((int(r[0]), int(r[1])), float(r[2]))).join(predictions)\n",
    "    error = math.sqrt(rates_and_preds.map(lambda r: (r[1][0] - r[1][1])**2).mean())\n",
    "    errors[err] = error\n",
    "    err += 1\n",
    "    print('For rank %s the RMSE is %s' % (rank, error))\n",
    "    if error < min_error:\n",
    "        min_error = error\n",
    "        best_rank = rank\n",
    "\n",
    "print('The best model was trained with rank %s' % best_rank)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "hj9JPVh_u9UW"
   },
   "source": [
    "But let's explain this a little bit. First, let's have a look at how our predictions look."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "pMVn8MGqu9vv",
    "outputId": "06bdb182-3bd1-43aa-a0f3-947533dd9557"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[((599, 1840), 2.810698956379059),\n",
       " ((11, 1840), 3.200947961363606),\n",
       " ((541, 464), 1.9883823981273228)]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictions.take(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "zaM4f4LOvBln"
   },
   "source": [
    "Basically we have the UserID, the MovieID, and the Rating, as we have in our ratings dataset. In this case the predictions third element, the rating for that movie and user, is the predicted by our ALS model. </br>\n",
    "\n",
    "Then we join these with our validation data (the one that includes ratings) and the result looks as follows:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "_GyUOUfwvElr",
    "outputId": "21c80f1b-a82b-42fd-e67e-add9ed1d0232"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[((1, 3441), (5.0, 3.1102835455971096)),\n",
       " ((2, 48516), (4.0, 4.031505238416239)),\n",
       " ((2, 80906), (5.0, 3.4547736883276197))]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rates_and_preds.take(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "GfN-PyDrvLNT"
   },
   "source": [
    "To that, we apply a squared difference and the we use the `mean()` action to get the MSE and apply `sqrt`. </br>\n",
    "\n",
    "Finally we test the selected model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "IcQRnOdSvON8",
    "outputId": "881ae87e-a23a-4810-dc4f-e1439750a056"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "23/04/14 01:53:14 WARN BlockManager: Task 1368 already completed, not releasing lock for rdd_3_0\n",
      "23/04/14 01:53:14 WARN BlockManager: Task 1370 already completed, not releasing lock for rdd_3_0\n",
      "23/04/14 01:53:17 WARN BlockManager: Task 1765 already completed, not releasing lock for rdd_3_0\n",
      "[Stage 771:================================================>      (16 + 2) / 18]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For testing data the RMSE is 0.908279077289237\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "model = ALS.train(training_RDD, best_rank, seed=seed, iterations=iterations,\n",
    "                      lambda_=regularization_parameter)\n",
    "predictions = model.predictAll(test_for_predict_RDD).map(lambda r: ((r[0], r[1]), r[2]))\n",
    "rates_and_preds = test_RDD.map(lambda r: ((int(r[0]), int(r[1])), float(r[2]))).join(predictions)\n",
    "error = math.sqrt(rates_and_preds.map(lambda r: (r[1][0] - r[1][1])**2).mean())\n",
    "    \n",
    "print('For testing data the RMSE is %s' % (error))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "LtVn-Iq7vZJE"
   },
   "source": [
    "## Using the complete dataset to build the final model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "oMWvk2ICvdOI"
   },
   "source": [
    "In order to build our recommender model, we will use the complete dataset. Therefore, we need to process it the same way we did with the small dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "UQW8rU1XvaMy",
    "outputId": "12d899fb-5ffc-4691-918b-c9b7cba0c3f3"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 774:========================================>              (17 + 6) / 23]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 27753444 recommendations in the complete dataset\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "# Load the complete dataset file\n",
    "complete_ratings_file = os.path.join(datasets_path, 'ml-latest', 'ratings.csv')\n",
    "complete_ratings_raw_data = sc.textFile(complete_ratings_file)\n",
    "complete_ratings_raw_data_header = complete_ratings_raw_data.take(1)[0]\n",
    "\n",
    "# Parse\n",
    "complete_ratings_data = complete_ratings_raw_data.filter(lambda line: line!=complete_ratings_raw_data_header)\\\n",
    "    .map(lambda line: line.split(\",\")).map(lambda tokens: (int(tokens[0]),int(tokens[1]),float(tokens[2]))).cache()\n",
    "    \n",
    "print(\"There are %s recommendations in the complete dataset\" % (complete_ratings_data.count()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "_oiprgsxwgJ0"
   },
   "source": [
    "Now we are ready to train the recommender model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "id": "LNlBDPC6wgj5"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "23/04/14 01:53:38 WARN BlockManager: Task 1846 already completed, not releasing lock for rdd_939_0\n",
      "ERROR:root:KeyboardInterrupt while sending command.                 (0 + 1) / 1]\n",
      "Traceback (most recent call last):\n",
      "  File \"/Applications/anaconda3/lib/python3.10/site-packages/py4j/java_gateway.py\", line 1038, in send_command\n",
      "    response = connection.send_command(command)\n",
      "  File \"/Applications/anaconda3/lib/python3.10/site-packages/py4j/clientserver.py\", line 475, in send_command\n",
      "    answer = smart_decode(self.stream.readline()[:-1])\n",
      "  File \"/Applications/anaconda3/lib/python3.10/socket.py\", line 705, in readinto\n",
      "    return self._sock.recv_into(b)\n",
      "KeyboardInterrupt\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[17], line 3\u001b[0m\n\u001b[1;32m      1\u001b[0m training_RDD, test_RDD \u001b[38;5;241m=\u001b[39m complete_ratings_data\u001b[38;5;241m.\u001b[39mrandomSplit([\u001b[38;5;241m7\u001b[39m, \u001b[38;5;241m3\u001b[39m], seed\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m)\n\u001b[0;32m----> 3\u001b[0m complete_model \u001b[38;5;241m=\u001b[39m \u001b[43mALS\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtraining_RDD\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbest_rank\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mseed\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mseed\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[1;32m      4\u001b[0m \u001b[43m                           \u001b[49m\u001b[43miterations\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43miterations\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlambda_\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mregularization_parameter\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/Applications/anaconda3/lib/python3.10/site-packages/pyspark/mllib/recommendation.py:280\u001b[0m, in \u001b[0;36mALS.train\u001b[0;34m(cls, ratings, rank, iterations, lambda_, blocks, nonnegative, seed)\u001b[0m\n\u001b[1;32m    243\u001b[0m \u001b[38;5;129m@classmethod\u001b[39m\n\u001b[1;32m    244\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mtrain\u001b[39m(\u001b[38;5;28mcls\u001b[39m, ratings, rank, iterations\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m5\u001b[39m, lambda_\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0.01\u001b[39m, blocks\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m, nonnegative\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[1;32m    245\u001b[0m           seed\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[1;32m    246\u001b[0m     \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    247\u001b[0m \u001b[38;5;124;03m    Train a matrix factorization model given an RDD of ratings by users\u001b[39;00m\n\u001b[1;32m    248\u001b[0m \u001b[38;5;124;03m    for a subset of products. The ratings matrix is approximated as the\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    278\u001b[0m \u001b[38;5;124;03m        (default: None)\u001b[39;00m\n\u001b[1;32m    279\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 280\u001b[0m     model \u001b[38;5;241m=\u001b[39m \u001b[43mcallMLlibFunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mtrainALSModel\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mcls\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_prepare\u001b[49m\u001b[43m(\u001b[49m\u001b[43mratings\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrank\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43miterations\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    281\u001b[0m \u001b[43m                          \u001b[49m\u001b[43mlambda_\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mblocks\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnonnegative\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mseed\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    282\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m MatrixFactorizationModel(model)\n",
      "File \u001b[0;32m/Applications/anaconda3/lib/python3.10/site-packages/pyspark/mllib/common.py:125\u001b[0m, in \u001b[0;36mcallMLlibFunc\u001b[0;34m(name, *args)\u001b[0m\n\u001b[1;32m    123\u001b[0m sc \u001b[38;5;241m=\u001b[39m SparkContext\u001b[38;5;241m.\u001b[39mgetOrCreate()\n\u001b[1;32m    124\u001b[0m api \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mgetattr\u001b[39m(sc\u001b[38;5;241m.\u001b[39m_jvm\u001b[38;5;241m.\u001b[39mPythonMLLibAPI(), name)\n\u001b[0;32m--> 125\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mcallJavaFunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43msc\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mapi\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/Applications/anaconda3/lib/python3.10/site-packages/pyspark/mllib/common.py:118\u001b[0m, in \u001b[0;36mcallJavaFunc\u001b[0;34m(sc, func, *args)\u001b[0m\n\u001b[1;32m    116\u001b[0m \u001b[38;5;124;03m\"\"\" Call Java Function \"\"\"\u001b[39;00m\n\u001b[1;32m    117\u001b[0m args \u001b[38;5;241m=\u001b[39m [_py2java(sc, a) \u001b[38;5;28;01mfor\u001b[39;00m a \u001b[38;5;129;01min\u001b[39;00m args]\n\u001b[0;32m--> 118\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m _java2py(sc, \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m)\n",
      "File \u001b[0;32m/Applications/anaconda3/lib/python3.10/site-packages/py4j/java_gateway.py:1320\u001b[0m, in \u001b[0;36mJavaMember.__call__\u001b[0;34m(self, *args)\u001b[0m\n\u001b[1;32m   1313\u001b[0m args_command, temp_args \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_build_args(\u001b[38;5;241m*\u001b[39margs)\n\u001b[1;32m   1315\u001b[0m command \u001b[38;5;241m=\u001b[39m proto\u001b[38;5;241m.\u001b[39mCALL_COMMAND_NAME \u001b[38;5;241m+\u001b[39m\\\n\u001b[1;32m   1316\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcommand_header \u001b[38;5;241m+\u001b[39m\\\n\u001b[1;32m   1317\u001b[0m     args_command \u001b[38;5;241m+\u001b[39m\\\n\u001b[1;32m   1318\u001b[0m     proto\u001b[38;5;241m.\u001b[39mEND_COMMAND_PART\n\u001b[0;32m-> 1320\u001b[0m answer \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgateway_client\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msend_command\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcommand\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1321\u001b[0m return_value \u001b[38;5;241m=\u001b[39m get_return_value(\n\u001b[1;32m   1322\u001b[0m     answer, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mgateway_client, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtarget_id, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mname)\n\u001b[1;32m   1324\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m temp_arg \u001b[38;5;129;01min\u001b[39;00m temp_args:\n",
      "File \u001b[0;32m/Applications/anaconda3/lib/python3.10/site-packages/py4j/java_gateway.py:1038\u001b[0m, in \u001b[0;36mGatewayClient.send_command\u001b[0;34m(self, command, retry, binary)\u001b[0m\n\u001b[1;32m   1036\u001b[0m connection \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_get_connection()\n\u001b[1;32m   1037\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m-> 1038\u001b[0m     response \u001b[38;5;241m=\u001b[39m \u001b[43mconnection\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msend_command\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcommand\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1039\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m binary:\n\u001b[1;32m   1040\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m response, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_create_connection_guard(connection)\n",
      "File \u001b[0;32m/Applications/anaconda3/lib/python3.10/site-packages/py4j/clientserver.py:475\u001b[0m, in \u001b[0;36mClientServerConnection.send_command\u001b[0;34m(self, command)\u001b[0m\n\u001b[1;32m    473\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m    474\u001b[0m     \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n\u001b[0;32m--> 475\u001b[0m         answer \u001b[38;5;241m=\u001b[39m smart_decode(\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstream\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mreadline\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m[:\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m])\n\u001b[1;32m    476\u001b[0m         logger\u001b[38;5;241m.\u001b[39mdebug(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mAnswer received: \u001b[39m\u001b[38;5;132;01m{0}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mformat(answer))\n\u001b[1;32m    477\u001b[0m         \u001b[38;5;66;03m# Happens when a the other end is dead. There might be an empty\u001b[39;00m\n\u001b[1;32m    478\u001b[0m         \u001b[38;5;66;03m# answer before the socket raises an error.\u001b[39;00m\n",
      "File \u001b[0;32m/Applications/anaconda3/lib/python3.10/socket.py:705\u001b[0m, in \u001b[0;36mSocketIO.readinto\u001b[0;34m(self, b)\u001b[0m\n\u001b[1;32m    703\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n\u001b[1;32m    704\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 705\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_sock\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrecv_into\u001b[49m\u001b[43m(\u001b[49m\u001b[43mb\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    706\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m timeout:\n\u001b[1;32m    707\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_timeout_occurred \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "training_RDD, test_RDD = complete_ratings_data.randomSplit([7, 3], seed=0)\n",
    "\n",
    "complete_model = ALS.train(training_RDD, best_rank, seed=seed, \n",
    "                           iterations=iterations, lambda_=regularization_parameter)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "WfyDq5z6wn_y"
   },
   "source": [
    "Now we test on our testing set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "yr3b6jLFwop2",
    "outputId": "5e657e4c-3ae0-49e2-dcb9-c0e86289135a"
   },
   "outputs": [],
   "source": [
    "test_for_predict_RDD = test_RDD.map(lambda x: (x[0], x[1]))\n",
    "\n",
    "predictions = complete_model.predictAll(test_for_predict_RDD).map(lambda r: ((r[0], r[1]), r[2]))\n",
    "rates_and_preds = test_RDD.map(lambda r: ((int(r[0]), int(r[1])), float(r[2]))).join(predictions)\n",
    "error = math.sqrt(rates_and_preds.map(lambda r: (r[1][0] - r[1][1])**2).mean())\n",
    "    \n",
    "print('For testing data the RMSE is %s' % (error))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "WKnavmtVypfd"
   },
   "source": [
    "We can see how we got a more accurate recommender when using a much larger dataset."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "nsAIogFfyvac"
   },
   "source": [
    "## How to make recommendations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "S07qlJsSyzxI"
   },
   "source": [
    "Although we aim at building an on-line movie recommender, now that we know how to have our recommender model ready, we can give it a try providing some movie recommendations. This will help us coiding the recommending engine later on when building the web service, and will explain how to use the model in any other circumstances."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Z6y9A3Vxy30r"
   },
   "source": [
    "When using collaborative filtering, getting recommendations is not as simple as predicting for the new entries using a previously generated model. Instead, we need to train again the model but including the new user preferences in order to compare them with other users in the dataset. That is, the recommender needs to be trained every time we have new user ratings (although a single model can be used by multiple users of course!). This makes the process expensive, and it is one of the reasons why scalability is a problem (and Spark a solution!). Once we have our model trained, we can reuse it to obtain top recomendations for a given user or an individual rating for a particular movie. These are less costly operations than training the model itself."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "FFdK88c6y62c"
   },
   "source": [
    "So let's first load the movies complete file for later use."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "QfDddpGoy7M9",
    "outputId": "b70bc726-bded-4834-e89f-718eb0a8b5c3"
   },
   "outputs": [],
   "source": [
    "complete_movies_file = os.path.join(datasets_path, 'ml-latest', 'movies.csv')\n",
    "complete_movies_raw_data = sc.textFile(complete_movies_file)\n",
    "complete_movies_raw_data_header = complete_movies_raw_data.take(1)[0]\n",
    "\n",
    "# Parse\n",
    "complete_movies_data = complete_movies_raw_data.filter(lambda line: line!=complete_movies_raw_data_header)\\\n",
    "    .map(lambda line: line.split(\",\")).map(lambda tokens: (int(tokens[0]),tokens[1],tokens[2])).cache()\n",
    "\n",
    "complete_movies_titles = complete_movies_data.map(lambda x: (int(x[0]),x[1]))\n",
    "    \n",
    "print(\"There are %s movies in the complete dataset\" % (complete_movies_titles.count()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "_mkz7Dk10H7b"
   },
   "source": [
    "Another thing we want to do, is give recommendations of movies with a certain minimum number of ratings. For that, we need to count the number of ratings per movie."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "vUm-Dhiw0IgL"
   },
   "outputs": [],
   "source": [
    "def get_counts_and_averages(ID_and_ratings_tuple):\n",
    "    nratings = len(ID_and_ratings_tuple[1])\n",
    "    return ID_and_ratings_tuple[0], (nratings, float(sum(x for x in ID_and_ratings_tuple[1]))/nratings)\n",
    "\n",
    "movie_ID_with_ratings_RDD = (complete_ratings_data.map(lambda x: (x[1], x[2])).groupByKey())\n",
    "movie_ID_with_avg_ratings_RDD = movie_ID_with_ratings_RDD.map(get_counts_and_averages)\n",
    "movie_rating_counts_RDD = movie_ID_with_avg_ratings_RDD.map(lambda x: (x[0], x[1][0]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "cTN4h_On0NSp"
   },
   "source": [
    "## Adding new user ratings"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Mi7qDpoD0S0B"
   },
   "source": [
    "Now we need to rate some movies for the new user. We will put them in a new RDD and we will use the user ID 0, that is not assigned in the MovieLens dataset. Check the [dataset](http://grouplens.org/datasets/movielens/) movies file for ID to Tittle assignment (so you know what movies are you actually rating)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "7kDxQIQ70OT1",
    "outputId": "30e0d012-1357-484d-a8a3-6ad7ccbb229b"
   },
   "outputs": [],
   "source": [
    "new_user_ID = 0\n",
    "\n",
    "# The format of each line is (userID, movieID, rating)\n",
    "new_user_ratings = [\n",
    "     (0,260,9), # Star Wars (1977)\n",
    "     (0,1,8), # Toy Story (1995)\n",
    "     (0,16,7), # Casino (1995)\n",
    "     (0,25,8), # Leaving Las Vegas (1995)\n",
    "     (0,32,9), # Twelve Monkeys (a.k.a. 12 Monkeys) (1995)\n",
    "     (0,335,4), # Flintstones, The (1994)\n",
    "     (0,379,3), # Timecop (1994)\n",
    "     (0,296,7), # Pulp Fiction (1994)\n",
    "     (0,858,10) , # Godfather, The (1972)\n",
    "     (0,50,8) # Usual Suspects, The (1995)\n",
    "    ]\n",
    "new_user_ratings_RDD = sc.parallelize(new_user_ratings)\n",
    "print('New user ratings: %s' % new_user_ratings_RDD.take(10))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "4PziNOpe0a-i"
   },
   "source": [
    "Now we add them to the data we will use to train our recommender model. We use Spark's `union()` transformation for this."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ENT1noof0ct1"
   },
   "outputs": [],
   "source": [
    "complete_data_with_new_ratings_RDD = complete_ratings_data.union(new_user_ratings_RDD)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "aij8ScEH0deq"
   },
   "source": [
    "And finally we train the ALS model using all the parameters we selected before (when using the small dataset)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "3ZcIfmHx1lZH"
   },
   "source": [
    "Setup Google COlaboratory for adding new user ratings because environtment not support."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "j2Gh-7120fJN",
    "outputId": "60c51002-7c98-46da-b70c-707d2298db9b"
   },
   "outputs": [],
   "source": [
    "from time import time\n",
    "\n",
    "t0 = time()\n",
    "new_ratings_model = ALS.train(complete_data_with_new_ratings_RDD, best_rank, seed=seed, \n",
    "                              iterations=iterations, lambda_=regularization_parameter)\n",
    "tt = time() - t0\n",
    "\n",
    "print(\"New model trained in %s seconds\" % round(tt,3))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "nKuKUufb0lME"
   },
   "source": [
    "It took some time. We will need to repeat that every time a user add new ratings. Ideally we will do this in batches, and not for every single rating that comes into the system for every user."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "1XfSgk-20lwy"
   },
   "source": [
    "## Getting top recommendations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "iELKtxVN0nFI"
   },
   "source": [
    "Let's now get some recommendations! For that we will get an RDD with all the movies the new user hasn't rated yet. We will them together with the model to predict ratings."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "w_Bt5XZI0oLo"
   },
   "outputs": [],
   "source": [
    "new_user_ratings_ids = map(lambda x: x[1], new_user_ratings) # get just movie IDs\n",
    "# keep just those not on the ID list (thanks Lei Li for spotting the error!)\n",
    "new_user_unrated_movies_RDD = (complete_movies_data.filter(lambda x: x[0] not in new_user_ratings_ids).map(lambda x: (new_user_ID, x[0])))\n",
    "\n",
    "# Use the input RDD, new_user_unrated_movies_RDD, with new_ratings_model.predictAll() to predict new ratings for the movies\n",
    "new_user_recommendations_RDD = new_ratings_model.predictAll(new_user_unrated_movies_RDD)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "uI3YXDQl0Rao"
   },
   "source": [
    "We have our recommendations ready. Now we can print out the 25 movies with the highest predicted ratings. And join them with the movies RDD to get the titles, and ratings count in order to get movies with a minimum number of counts. First we will do the join and see what does the result looks like."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "OXDP8Rt70R_W",
    "outputId": "0ad7efcf-4cd5-4438-b7b4-018e78e6095d"
   },
   "outputs": [],
   "source": [
    "# Transform new_user_recommendations_RDD into pairs of the form (Movie ID, Predicted Rating)\n",
    "new_user_recommendations_rating_RDD = new_user_recommendations_RDD.map(lambda x: (x.product, x.rating))\n",
    "new_user_recommendations_rating_title_and_count_RDD = \\\n",
    "    new_user_recommendations_rating_RDD.join(complete_movies_titles).join(movie_rating_counts_RDD)\n",
    "new_user_recommendations_rating_title_and_count_RDD.take(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ncv53WB00U_I"
   },
   "source": [
    "So we need to flat this down a bit in order to have `(Title, Rating, Ratings Count)`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "0cbqEYyA0XBJ"
   },
   "outputs": [],
   "source": [
    "new_user_recommendations_rating_title_and_count_RDD = \\\n",
    "    new_user_recommendations_rating_title_and_count_RDD.map(lambda r: (r[1][0][1], r[1][0][0], r[1][1]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "RX4Ta9f80cb2"
   },
   "source": [
    "Finally, get the highest rated recommendations for the new user, filtering out movies with less than 25 ratings."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "2Qj8e3Zt0dFv",
    "outputId": "748adcca-8142-4faf-88e5-ae70476dcf28"
   },
   "outputs": [],
   "source": [
    "top_movies = new_user_recommendations_rating_title_and_count_RDD.filter(lambda r: r[2]>=25).takeOrdered(25, key=lambda x: -x[1])\n",
    "\n",
    "print ('TOP recommended movies (with more than 25 reviews):\\n%s' %\n",
    "        '\\n'.join(map(str, top_movies)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Sgf0Lsg602hn"
   },
   "source": [
    "## Getting individual ratings"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "vpnKD8c106lQ"
   },
   "source": [
    "Another useful usecase is getting the predicted rating for a particular movie for a given user. The process is similar to the previous retreival of top recommendations but, instead of using `predcitAll` with every single movie the user hasn't rated yet, we will just pass the method a single entry with the movie we want to predict the rating for."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "hBV_4qAT09T_",
    "outputId": "3df91fbb-4070-4468-a5d9-eb62ac9ddf3d"
   },
   "outputs": [],
   "source": [
    "my_movie = sc.parallelize([(0, 500)]) # Quiz Show (1994)\n",
    "individual_movie_rating_RDD = new_ratings_model.predictAll(new_user_unrated_movies_RDD)\n",
    "individual_movie_rating_RDD.take(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "BpE6CeOm0_bV"
   },
   "source": [
    "Not very likely that the new user will like that one... Obviously we can include as many movies as we need in that list!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "XQ31lHMk1BBl"
   },
   "source": [
    "## Persisting the model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "XJX1tNiQ1CNP"
   },
   "source": [
    "Optionally, we might want to persist the base model for later use in our on-line recommendations. Although a new model is generated everytime we have new user ratings, it might be worth it to store the current one, in order to save time when starting up the server, etc. We might also save time if we persist some of the RDDs we have generated, specially those that took longer to process. For example, the following lines save and load a ALS model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "0iGD4Q6p1Afq"
   },
   "outputs": [],
   "source": [
    "from pyspark.mllib.recommendation import MatrixFactorizationModel\n",
    "\n",
    "model_path = os.path.join('..', 'models', 'movie_lens_als')\n",
    "\n",
    "# Save and load model\n",
    "model.save(sc, model_path)\n",
    "same_model = MatrixFactorizationModel.load(sc, model_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Nr6-N2ZL1PWk"
   },
   "source": [
    "Among other things, you will see in your filesystem that there are folder with product and user data into [Parquet](https://parquet.apache.org/) format files."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "qrde0BSG1PwX"
   },
   "source": [
    "## Genre and other fields"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "i-u7DW3X1UTu"
   },
   "source": [
    "We havent used the `genre` and `timestamp` fields in order to simplify the transformations and the whole tutorial. Incorporating them doesn't reprensent any problem. A good use could be filtering recommendations by any of them (e.g. recommendations by genre, or recent recommendations) like we have done with the minimum number of ratings."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "x4RsQDye1U-r"
   },
   "source": [
    "# Big Data Exercise"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "6P8C_JAn1lNf"
   },
   "source": [
    "In the example, rank is the only hyperparameter with value variation. Add additional inner loop to combine it with iteration using values 5, 10, and 20."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "JMvhrFwH1XzU"
   },
   "outputs": [],
   "source": [
    "ranks = [4, 8, 12]\n",
    "iterations = [5, 10, 20]\n",
    "lambda_ = 0.1\n",
    "tolerance = 0.02\n",
    "min_error = float('inf')\n",
    "best_rank = -1\n",
    "best_iteration = -1\n",
    "results = []"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "make the inner loop more efficient is to use the persist() method to cache the model and predictions RDDs in memory. This can be useful if you are running multiple iterations with the same data, since it avoids having to recalculate the same RDDs each time."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "AYzNcWr81pQv",
    "outputId": "ac65e781-41e5-43b9-aa19-f5a8f805d51d"
   },
   "outputs": [],
   "source": [
    "for rank in ranks:\n",
    "    for iteration in iterations:\n",
    "        model = ALS.train(training_RDD, rank, seed=seed, iterations=iteration, lambda_=lambda_).persist()\n",
    "        predictions = model.predictAll(validation_RDD_for_prediction).map(lambda r: ((r[0], r[1]), r[2])).persist()\n",
    "        rates_and_preds = validation_RDD.map(lambda r: ((int(r[0]), int(r[1])), float(r[2]))).join(predictions)\n",
    "        error = math.sqrt(rates_and_preds.map(lambda r: (r[1][0] - r[1][1])**2).mean())\n",
    "        results.append({'rank': rank, 'iteration': iteration, 'error': error})\n",
    "        print(f'Rank: {rank}, Iteration: {iteration}, RMSE: {error}')\n",
    "        if error < min_error:\n",
    "            min_error = error\n",
    "            best_rank = rank\n",
    "            best_iteration = iteration\n",
    "\n",
    "        # unpersist the RDDs to free up memory\n",
    "        model.unpersist()\n",
    "        predictions.unpersist()\n",
    "\n",
    "print(f'The best model has Rank {best_rank} and Iteration {best_iteration}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(results[0]['rank']) # Output: 4\n",
    "print(results[0]['iteration']) # Output: 5\n",
    "print(results[0]['error']) # Output: 1.2365"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "authorship_tag": "ABX9TyO1RGnCG8iJwVJ5OweXEfI5",
   "include_colab_link": true,
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
